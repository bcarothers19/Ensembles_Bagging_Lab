{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees and Ensembles Lab\n",
    "\n",
    "In this lab we will compare the performance of a simple Decision Tree classifier with a Bagging classifier. We will do that on few datasets, starting from the ones offered by Scikit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Breast Cancer Dataset\n",
    "We will start our comparison on the breast cancer dataset.\n",
    "You can load it directly from scikit-learn using the `load_breast_cancer` function.\n",
    "\n",
    "### 1.a Simple comparison\n",
    "1. Load the data and create X and Y.\n",
    "- Initialize a Decision Tree Classifier and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds.\n",
    "- Wrap a Bagging Classifier around the Decision Tree Classifier and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds. \n",
    "- Which score is better? Are the score significantly different? How can you judge that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data and set out features and target\n",
    "bc = datasets.load_breast_cancer()\n",
    "X = bc.data\n",
    "y = bc.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC score: 0.919169\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Decision Tree Classifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "# Use cross_val_score to evaluate DTC performance\n",
    "print 'DTC score: %f' % cross_val_score(dtc,X,y,cv=5,n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging score: 0.954475\n"
     ]
    }
   ],
   "source": [
    "# Wrap a Bagging Classifier around the DTC\n",
    "bagging = BaggingClassifier(DecisionTreeClassifier())\n",
    "# Use cross_val_score to evaluate performance with bagging\n",
    "print 'Bagging score: %f' % cross_val_score(bagging,X,y,cv=5,n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We see that score when using bagging is significantly better than a regular decision tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b Scale (normalize) data\n",
    "As you may have noticed the features are not normalized. Do the score improve with normalization?\n",
    "\n",
    "1. Normalize the predictors.\n",
    "2. Build a decision tree classifier and bagging decision tree classifier.\n",
    "3. Are scores different from non-scaled data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize the predictors\n",
    "Xs = preprocessing.normalize(X,norm='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC score: 0.936745\n",
      "Bagging score: 0.957830\n"
     ]
    }
   ],
   "source": [
    "# Build a DTC and Bagging Classifier and check the cross val scores\n",
    "dtc = DecisionTreeClassifier()\n",
    "print 'DTC score: %f' % cross_val_score(dtc,Xs,y,cv=5,n_jobs=-1).mean()\n",
    "bagging = BaggingClassifier(DecisionTreeClassifier())\n",
    "print 'Bagging score: %f' % cross_val_score(bagging,Xs,y,cv=5,n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We see that the scores aren't different than the non-normalized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c Grid Search\n",
    "\n",
    "Grid search is a great way to improve the performance of a classifier. Let's explore the parameter space of both models and see if we can improve their performance.\n",
    "\n",
    "1. Initialize a GridSearchCV with 5-fold cross validation for the Decision Tree Classifier.\n",
    "2. Search for few parameter values to try and improve the score of the classifier.\n",
    "4. Check the best\\_score\\_ once you've trained it. Is it better than before?\n",
    "5. How does the score of the Grid-searched DT compare with the score of the Bagging DT?\n",
    "6. Initialize a GridSearchCV with 5-fold cross validation for the Bagging Decision Tree Classifier\n",
    "7. Repeat the search\n",
    "    - Note that you'll have to change parameter names for the base_estimator (see example).\n",
    "    - Note that there are also additional parameters to change (see example).\n",
    "    - Note that you may end up with a grid space to large to search in a short time - choose smaller ranges of parameters!\n",
    "    - Make use of the n_jobs parameter to speed up your grid search (-1 uses all cores).\n",
    "8. Does the score improve for the Grid-searched Bagging Classifier?\n",
    "9. Which score is better? Are the score significantly different? How could/would you judge that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the parameters for our first grid search\n",
    "params = {'max_features': range(1,31),\n",
    "          'max_depth': range(1,21),\n",
    "          'min_samples_split': [2,5,7],\n",
    "          'min_samples_leaf': [1,3,5,7,10]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9000 candidates, totalling 45000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 912 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 5112 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 12112 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 21912 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=-1)]: Done 34512 tasks      | elapsed:   37.1s\n",
      "[Parallel(n_jobs=-1)]: Done 45000 out of 45000 | elapsed:   48.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], 'min_samples_split': [2, 5, 7], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'min_samples_leaf': [1, 3, 5, 7, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a grid search on a Decision Tree Classifier\n",
    "grid = GridSearchCV(DecisionTreeClassifier(),params,cv=5,n_jobs=-1,verbose=1)\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score using GridSearch on DTC: 0.956063\n"
     ]
    }
   ],
   "source": [
    "print 'Best score using GridSearch on DTC: %f' % grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set the parameters for our grid search using bagging\n",
    "params = {\"base_estimator__max_depth\": [3,5,10,20],\n",
    "          \"base_estimator__max_features\": [None,\"auto\"],\n",
    "          \"base_estimator__min_samples_leaf\": [1, 3, 5, 7, 10],\n",
    "          \"base_estimator__min_samples_split\": [2, 5, 7],\n",
    "          'bootstrap_features': [False, True],\n",
    "          'max_features': [0.5, 0.7, 1.0],\n",
    "          'max_samples': [0.5, 0.7, 1.0],\n",
    "          'n_estimators': [2, 5, 10, 20],\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8640 candidates, totalling 43200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3736 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done 8736 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=-1)]: Done 15736 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 24736 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 35736 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 43200 out of 43200 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, ...n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [2, 5, 10, 20], 'max_samples': [0.5, 0.7, 1.0], 'base_estimator__min_samples_split': [2, 5, 7], 'base_estimator__max_depth': [3, 5, 10, 20], 'bootstrap_features': [False, True], 'max_features': [0.5, 0.7, 1.0], 'base_estimator__min_samples_leaf': [1, 3, 5, 7, 10], 'base_estimator__max_features': [None, 'auto']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a GridSearchCV with 5-fold cross validation for the Bagging Decision Tree Classifier\n",
    "bdtc = BaggingClassifier(DecisionTreeClassifier())\n",
    "# Perform the grid search\n",
    "grid = GridSearchCV(bdtc,params,cv=5,n_jobs=-1,verbose=1)\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score using GridSearch on Bagging DTC: 0.971880\n"
     ]
    }
   ],
   "source": [
    "print 'Best score using GridSearch on Bagging DTC: %f' % grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grid searching a Bagging DTC gives us the best score.\n",
    "# The improvement over other methods is significant.\n",
    "# I judge the score by looking at them. A change of .002 to the score would be insignificant, but a change of .02 like we saw here is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Diabetes and Regression\n",
    "\n",
    "Scikit Learn has a dataset of diabetic patients obtained from this study:\n",
    "\n",
    "http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
    "http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf\n",
    "\n",
    "442 diabetes patients were measured on 10 baseline variables: age, sex, body mass index, average blood pressure, and six blood serum measurements.\n",
    "\n",
    "The target is a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "Repeat the above comparison between a DecisionTreeRegressor and a Bagging Regressor instead of classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a Simple comparison\n",
    "1. Load the data and create X and Y\n",
    "2. Initialize a Decision Tree Regressor and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds. What does the score mean (look at documentation!).\n",
    "3. Wrap a Bagging Regressor around the Decision Tree Regressor and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds. \n",
    "4. Which score is better? Are the score significantly different? How could/would you judge that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data and set the features and target\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTR score: -0.164144\n"
     ]
    }
   ],
   "source": [
    "# Initialize a DTR and evaluate it's performance using cross_val_score\n",
    "dtr = DecisionTreeRegressor()\n",
    "print 'DTR score: %f' % cross_val_score(dtr,X,y,cv=5,n_jobs=-1,scoring='r2').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This r2 score means there is a very weak negative correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging score: 0.367130\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Bagging DTR and evaluate it's performance using cross_val_score\n",
    "bdtr = BaggingRegressor(DecisionTreeRegressor())\n",
    "print 'Bagging score: %f' % cross_val_score(bdtr,X,y,cv=5,n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The r2 score of the bagging regressor is much better than just the DTR.\n",
    "# It is signficantly better, but 0.36 is still not a very good r2 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b Grid Search\n",
    "\n",
    "Repeat Grid search as above:\n",
    "\n",
    "1. Initialize a GridSearchCV with 5-fold cross validation for the Decision Tree Regressor.\n",
    "2. Search for few values of the parameters in order to improve the score of the regressor.\n",
    "3. Check the best\\_score\\_ once you've trained it. Is it better than before?\n",
    "4. How does the score of the Grid-searched DT compare with the score of the Bagging DT?\n",
    "5. Initialize a GridSearchCV with 5-fold cross validation for the Bagging Decision Tree Regressor\n",
    "6. Repeat the search\n",
    "    - Note that you'll have to change parameter names for the base_estimator.\n",
    "    - Note that there are also additional parameters to change.\n",
    "    - Note that you may end up with a grid space to large to search in a short time.\n",
    "    - Make use of the n_jobs parameter to speed up your grid search.\n",
    "7. Does the score improve for the Grid-searched Bagging Regressor?\n",
    "8. Which score is better? Are the score significantly different? How could/would you judge that?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the parameters for our first grid search\n",
    "params = {'max_features': range(1,11),\n",
    "          'max_depth': range(1,11),\n",
    "          'min_samples_split': [2,5,7],\n",
    "          'min_samples_leaf': [1,3,5,7,10]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1500 candidates, totalling 7500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 4540 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 7500 out of 7500 | elapsed:    7.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "           splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_split': [2, 5, 7], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [1, 3, 5, 7, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a grid search on a Decision Tree Regressor\n",
    "grid = GridSearchCV(DecisionTreeRegressor(),params,cv=5,n_jobs=-1,verbose=1)\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score using GridSearch on DTR: 0.378855\n"
     ]
    }
   ],
   "source": [
    "print 'Best score using GridSearch on DTR: %f' % grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The GridSearch on a DTR gives us a slightly better score than a Bagging DTR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the parameters for our grid search using bagging\n",
    "params = {\"base_estimator__max_depth\": [3,5,10,20],\n",
    "          \"base_estimator__max_features\": [None,\"auto\"],\n",
    "          \"base_estimator__min_samples_leaf\": [1, 3, 5, 7, 10],\n",
    "          \"base_estimator__min_samples_split\": [2, 5, 7],\n",
    "          'bootstrap_features': [False, True],\n",
    "          'max_features': [0.5, 0.7, 1.0],\n",
    "          'max_samples': [0.5, 0.7, 1.0],\n",
    "          'n_estimators': [2, 5, 10, 20],\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8640 candidates, totalling 43200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 432 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2832 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 6832 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 12432 tasks      | elapsed:   56.2s\n",
      "[Parallel(n_jobs=-1)]: Done 19632 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 28432 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 38832 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 43200 out of 43200 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=BaggingRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "           splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [2, 5, 10, 20], 'max_samples': [0.5, 0.7, 1.0], 'base_estimator__min_samples_split': [2, 5, 7], 'base_estimator__max_depth': [3, 5, 10, 20], 'bootstrap_features': [False, True], 'max_features': [0.5, 0.7, 1.0], 'base_estimator__min_samples_leaf': [1, 3, 5, 7, 10], 'base_estimator__max_features': [None, 'auto']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a GridSearchCV with 5-fold cross validation for the Bagging Decision Tree Regressor\n",
    "bdtr = BaggingRegressor(DecisionTreeRegressor())\n",
    "# Perform the grid search\n",
    "grid = GridSearchCV(bdtr,params,cv=5,n_jobs=-1,verbose=1)\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score using GridSearch on Bagging DTR: 0.471675\n"
     ]
    }
   ],
   "source": [
    "print 'Best score using GridSearch on Bagging DTR: %f' % grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using GridSearch on our Bagging DTR gives us the best score out of all the tested methods by a significant amount."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
